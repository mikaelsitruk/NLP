{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the article from https://www.kdnuggets.com/2020/01/intro-guide-nlp-data-scientists.html\n",
    "\n",
    "# 1. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization is the process of cutting text in sentences or words. This can be done with nltk, but first let's download what we need..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Mikael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'name', 'is', 'Mike', 'and', 'I', 'love', 'NLP', ',', 'I', 'live', 'in', 'New', 'Orleans', '.', 'New', 'York', 'is', 'a', 'beautiful', 'place', '!']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "sentence = \"My name is Mike and I love NLP, I live in New Orleans. New York is a beautiful place!\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This split the text into words, and ponctuations characters. \n",
    "Note: New York the city was \"understood\" as two words, there is not much of intelligence here...\n",
    "\n",
    "Interesting if we do it in French..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mon', 'nom', 'est', 'Mike', 'et', \"j'aime\", 'le', 'NLP', ',', \"j'habite\", 'a', 'Paris', 'mais', \"j'aime\", 'aussi', 'beaucoup', 'New-York', '!']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Mon nom est Mike et j'aime le NLP, j'habite a Paris mais j'aime aussi beaucoup New-York!\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting this time New-York was with a dash and was not split in two words, on the other hand \"j'aime\" should have been marked as two words but was seen as single one!\n",
    "\n",
    "__TODO: need to check how to process other than english texts...__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Stop word removal\n",
    "This step allows us to remove the noise from the text by removing the common words like \"the\", \"a\", \"and\"... to reduce the noise. Note that the punctuation is still present but \"is\", \"and\", \"in\",\"a\" were removed since defined as stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'name', 'Mike', 'I', 'love', 'NLP', ',', 'I', 'live', 'New', 'Orleans', '.', 'New', 'York', 'beautiful', 'place', '!']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mikael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sentence = \"My name is Mike and I love NLP, I live in New Orleans. New York is a beautiful place!\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "filtered_tokens = [w for w in tokens if w not in stop_words]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with the french sentence and a french dictionnary...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mon', 'nom', 'Mike', \"j'aime\", 'NLP', ',', \"j'habite\", 'a', 'Paris', \"j'aime\", 'aussi', 'beaucoup', 'New-York', '!']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mikael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sentence = \"Mon nom est Mike et j'aime le NLP, j'habite a Paris mais j'aime aussi beaucoup New-York!\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "stop_words = stopwords.words('french')\n",
    "filtered_tokens = [w for w in tokens if w not in stop_words]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So \"est\", \"et\", \"le\" , \"mais\" were removed, but was also expected to remove the \"a\" that indicate location and to have the \"j'\" as stand alone...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
